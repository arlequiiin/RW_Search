import sys
import os
import uuid
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.docs_parser import extract_text_with_filename, prepare_text_for_chunking
from src.chunker import split_text
from src.embeddings import EmbeddingModel
from src.storage import get_chroma
from src.config import EMBEDDING_MODEL_NAME, CHUNK_SIZE_TOKENS, CHUNK_OVERLAP_TOKENS


def ingest_document(file_path: str, active: bool = True, author: str = "unknown", tags: str = ""):
    print(f"\nüìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {file_path}")

    if not os.path.exists(file_path):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return False

    try:
        text, filename_without_ext = extract_text_with_filename(file_path)
        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {filename_without_ext}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
        return False

    text_with_header = prepare_text_for_chunking(text, filename_without_ext)
    chunks = split_text(text_with_header, max_length=CHUNK_SIZE_TOKENS * 4, overlap=CHUNK_OVERLAP_TOKENS * 4)
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤")

    if not chunks:
        print("‚ö†Ô∏è  –î–æ–∫—É–º–µ–Ω—Ç –ø—É—Å—Ç–æ–π, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
        return False

    print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
    embedding_model = EmbeddingModel(EMBEDDING_MODEL_NAME)
    embeddings = embedding_model.encode(chunks)
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(embeddings)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")

    doc_id = str(uuid.uuid4())
    filename = os.path.basename(file_path)
    created_at = datetime.now().isoformat()

    print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É...")
    client, collection = get_chroma()

    chunk_ids = []
    metadatas = []

    for i, chunk in enumerate(chunks):
        chunk_id = f"{doc_id}_chunk_{i}"
        chunk_ids.append(chunk_id)

        metadata = {
            'doc_id': doc_id,
            'filename': filename,
            'file_path': file_path,
            'chunk_index': i,
            'total_chunks': len(chunks),
            'active': active,
            'author': author,
            'tags': tags,
            'created_at': created_at
        }
        metadatas.append(metadata)

    collection.add(
        documents=chunks,
        embeddings=embeddings.tolist(),
        metadatas=metadatas,
        ids=chunk_ids
    )

    print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω!")
    print(f"   Doc ID: {doc_id}")
    print(f"   –ß–∞–Ω–∫–æ–≤: {len(chunks)}")
    print(f"   –ò–º—è —Ñ–∞–π–ª–∞: {filename}")

    return True


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è —Å–∫—Ä–∏–ø—Ç–∞"""
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python ingest_file.py <–ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É> [author] [tags]")
        print("\n–ü—Ä–∏–º–µ—Ä:")
        print("  python ingest_file.py data/docs/–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è.docx")
        print("  python ingest_file.py data/docs/–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è.docx '–ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤' '–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è,–≤–∞–∂–Ω–æ'")
        sys.exit(1)

    file_path = sys.argv[1]
    author = sys.argv[2] if len(sys.argv) > 2 else "unknown"
    tags = sys.argv[3] if len(sys.argv) > 3 else ""

    success = ingest_document(file_path, active=True, author=author, tags=tags)

    if success:
        print("\nüéâ –ì–æ—Ç–æ–≤–æ!")
    else:
        print("\n‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞")
        sys.exit(1)


if __name__ == "__main__":
    main()
