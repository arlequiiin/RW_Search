#!/usr/bin/env python3
"""–¢–µ—Å—Ç —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""

from sentence_transformers import SentenceTransformer, util

print("=" * 70)
print("–¢–ï–°–¢ –õ–£–ß–®–ò–• –ú–û–î–ï–õ–ï–ô –î–õ–Ø –†–£–°–°–ö–û–ì–û")
print("=" * 70)

query = "–∫–∞–∫ –Ω–∞–ø–∏—Å–∞—Ç—å —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è?"
documents = [
    "–ö–∞–∂–¥—ã–π –¥–µ–Ω—å –æ—Ç–¥–µ–ª –∑–∞–∫—Ä—ã—Ç–∏—è –ø–∏—à—É—Ç —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –º–µ–∂–¥—É 1 –∏ 3 —Ä–µ–≥–∏—Å—Ç—Ä–æ–º",
    "–ü–µ—Ä–µ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –æ—Ç–∫—Ä—ã—Ç—å –±–∞–∑—É",
    "–î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—Ä–∞—â–µ–Ω–∏—è —É–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è",
]

# –ú–æ–¥–µ–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ
models_to_test = [
    "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
    "cointegrated/rubert-tiny2",
]

for model_name in models_to_test:
    print(f"\nüî¨ –ú–æ–¥–µ–ª—å: {model_name}")
    
    try:
        model = SentenceTransformer(model_name)
        
        query_emb = model.encode(query, convert_to_tensor=True)
        doc_embs = model.encode(documents, convert_to_tensor=True)
        
        similarities = util.cos_sim(query_emb, doc_embs)[0]
        
        for i, sim in enumerate(similarities, 1):
            marker = "‚úÖ" if i == 1 else "  "
            print(f"{marker} [{i}] {sim.item()*100:.2f}% - {documents[i-1][:60]}...")
        
        best_idx = similarities.argmax().item()
        if best_idx == 0:
            print(f"‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ!")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞: –≤—ã–±—Ä–∞–ª [{best_idx+1}]")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")

print(f"\n{'='*70}")
